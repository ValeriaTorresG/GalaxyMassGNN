{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Neural Network (GNN)\n",
    "\n",
    "$$h_{i}^{t+1} = f\\left(h_{i}^{t} W + \\sum_{j \\in N (i)} \\frac{1}{C_{i,j}} h_{j}^{t} U \\right)$$\n",
    "\n",
    "Old representation times a weight matrix:\n",
    "$$h_{i}^{t} W $$\n",
    "\n",
    "Information from neighbors times a weight matrix:\n",
    "$$h_{j}^{t} U $$\n",
    "\n",
    "### Aggregation function:\n",
    "\n",
    "Sum over all transformed neighbor representations\n",
    "\n",
    "$$\\sum_{j \\in N (i)} \\frac{1}{C_{i,j}}$$\n",
    "\n",
    "Normalize the vectors differently for each neighbor\n",
    "$$\\frac{1}{C_{i,j}}$$\n",
    "\n",
    "The sum is a $permutation-invariant$ aggregation function -> Insensitive to $order$\n",
    "\n",
    "Each node's updated value becomes a weighting of its previous value+weightning of it's neighbors values.\n",
    "\n",
    "-> Agg function can be mean, max, concatenation, etc.\n",
    "\n",
    "\n",
    "\n",
    "Collapse $W_{self}$ and $W_{neigh}$ into $W$ by adding self-loops to the adjacency matrix $A$:\n",
    "$$H^{(k+1)} = \\sigma \\left( (A+I)H^{(k)} W^{k+1} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, DataParallel, Linear\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import csv\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph data\n",
    "<div style=\"text-align:center; display: flex; justify-content: center;\">\n",
    "  <table>\n",
    "    <tr>\n",
    "      <th>Rosette number</th>\n",
    "      <th>Nodes</th>\n",
    "      <th>Edges</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>11157</td>\n",
    "      <td>7572</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>9568</td>\n",
    "      <td>5245</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>11635</td>\n",
    "      <td>9257</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>11</td>\n",
    "      <td>13667</td>\n",
    "      <td>13051</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>12</td>\n",
    "      <td>10617</td>\n",
    "      <td>6870</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>13</td>\n",
    "      <td>13260</td>\n",
    "      <td>14395</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>14</td>\n",
    "      <td>10704</td>\n",
    "      <td>7635</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>15</td>\n",
    "      <td>10131</td>\n",
    "      <td>8655</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>18</td>\n",
    "      <td>11117</td>\n",
    "      <td>7991</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>19</td>\n",
    "      <td>10248</td>\n",
    "      <td>6689</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_r(r):\n",
    "\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    mass = []\n",
    "\n",
    "    with open(f'./data/rosette{r}_nodes.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            if (row!=0):\n",
    "                values = list(row.values())\n",
    "                n = []\n",
    "                n.append(float(values[0]))\n",
    "                n.extend(22.5-2.5*np.log10([float(n) for n in values[2:]]))\n",
    "                n.append(float(values[-1]))\n",
    "                nodes.append(n)\n",
    "                mass.append(float(values[2]))\n",
    "\n",
    "    with open(f'./data/rosette{r}_edges.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            if (row!=0):\n",
    "                edges.append([float(n) for n in list(row.values())])\n",
    "\n",
    "    return (nodes,edges,mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosettes = [3,6,7,11,12,13,14,15,18,19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, task='node'):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(26)\n",
    "\n",
    "        self.init_conv = GCNConv(graph.num_node_features, embedding_size)\n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size) #GAT or GCN?\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
    "        self.out = Linear(embedding_size*2, 1) #Regression problem\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        hidden = self.init_conv(x, edge_index)\n",
    "        hidden = nn.ReLU(hidden)\n",
    "\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = nn.ReLU(hidden)\n",
    "\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = nn.ReLU(hidden)\n",
    "\n",
    "        hidden = self.conv3(hidden, edge_index)\n",
    "        hidden = nn.ReLU(hidden)\n",
    "\n",
    "        #Global pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), gap(hidden, batch_index)], dim=1)\n",
    "        out = self.out(hidden)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (init_conv): GCNConv(8, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (out): Linear(128, 1, bias=True)\n",
      ")\n",
      "Number of parameters:  13185\n"
     ]
    }
   ],
   "source": [
    "model = GNN()\n",
    "\n",
    "embedding_size = 64\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges, mass = graph_r(rosettes[0])\n",
    "\n",
    "nodes_train, nodes_test, mass_train, mass_test = train_test_split(nodes, mass, test_size=0.8, random_state=26)\n",
    "\n",
    "nodes_train, nodes_test = torch.tensor(nodes_train, dtype=torch.float), torch.tensor(nodes_test, dtype=torch.float)\n",
    "mass_train, mass_test = torch.tensor(mass_train, dtype=torch.float), torch.tensor(mass_test, dtype=torch.float)\n",
    "\n",
    "edges = torch.tensor(edges, dtype=torch.long)\n",
    "edge_index = edges[:, :2].t().contiguous()\n",
    "\n",
    "graph_train = Data(x=nodes_train, edge_index=edge_index, edge_attr=edges[:, 2], y=mass_train)\n",
    "graph_test = Data(x=nodes_test, edge_index=edge_index, edge_attr=edges[:, 2], y=mass_test)\n",
    "\n",
    "graph_train.num_nodes = nodes_train.size(0)\n",
    "graph_test.num_nodes = nodes_test.size(0)\n",
    "graph_train.num_edges, graph_test.num_edges = edges.size(0), edges.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_per_batch = 64\n",
    "loader = DataLoader(graph_train, batch_size=graphs_per_batch, shuffle=True)\n",
    "test_loader = DataLoader(graph_test, batch_size=graphs_per_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto Teorico-Computacional/GalaxyMassGNN/gnn.ipynb Celda 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss, h \u001b[39m=\u001b[39m train(graph)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto Teorico-Computacional/GalaxyMassGNN/gnn.ipynb Celda 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(data):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Enumerate over the data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m       \u001b[39m# Use GPU\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       batch\u001b[39m.\u001b[39mto(device)  \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valeriatorresgomez/Library/CloudStorage/OneDrive-Universidaddelosandes/Escritorio/Universidad/2023-20/Proyecto%20Teorico-Computacional/GalaxyMassGNN/gnn.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       \u001b[39m# Reset gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/data/data.py:498\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 498\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/data/storage.py:111\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def train(data):\n",
    "    for batch in loader:\n",
    "      batch.to(device) #gpu\n",
    "      optimizer.zero_grad() #reset gradients\n",
    "      pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) #passing node features and connection info\n",
    "      loss = loss_fn(pred, batch.y) #calculate loss and gradients\n",
    "      loss.backward()\n",
    "      optimizer.step() #update using gradients\n",
    "    return loss, embedding\n",
    "\n",
    "number_epochs = 100\n",
    "losses = []\n",
    "for epoch in range(number_epochs):\n",
    "    loss, h = train(graph)\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "      print(f\"Epoch: {epoch} | Train Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses]\n",
    "loss_indices = [i for i,l in enumerate(losses_float)]\n",
    "plt = sns.lineplot(loss_indices, losses_float) #plot training loss\n",
    "plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
