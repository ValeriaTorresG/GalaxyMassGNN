{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, Linear, GATConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torchviz import make_dot\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.classes.function import density, degree\n",
    "from scipy.stats import pearsonr\n",
    "import optuna\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_r(r):\n",
    "\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    mass = []\n",
    "\n",
    "    with open(f'./data/rosette{r}_nodes.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            if (row!=0):\n",
    "                values = list(row.values())\n",
    "                n = []\n",
    "                n.append(float(values[0]))\n",
    "                n.extend(22.5-2.5*np.log10([float(n) for n in values[2:-1]]))\n",
    "                n.append(float(values[-1]))\n",
    "                nodes.append(n)\n",
    "                mass.append(float(values[1]))\n",
    "\n",
    "    with open(f'./data/rosette{r}_edges.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            if (row!=0):\n",
    "                edges.append([float(n) for n in list(row.values())])\n",
    "\n",
    "    return (nodes,edges,mass) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosettes = [3,6,7,11,12,13,14,15,18,19]\n",
    "props = ['log flux_g','log flux_r','log flux_z','log flux_w1','log flux_w2','z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges, mass = graph_r(rosettes[0])\n",
    "graph = nx.Graph()\n",
    "for i in range(len(nodes)):\n",
    "    graph.add_node(i, attr=nodes[i][1:])\n",
    "\n",
    "id_to_position = {node[0]: i for i, node in enumerate(nodes)}\n",
    "mapped_edges = [[id_to_position[edge[0]], id_to_position[edge[1]], edge[2]] for edge in edges]\n",
    "for edge in mapped_edges:\n",
    "    graph.add_edge(edge[0], edge[1], weight=edge[2])\n",
    "\n",
    "graph = graph.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor([[graph[u][v]['weight']] for u, v in graph.edges], dtype=torch.float)\n",
    "x = torch.tensor([graph.nodes[i]['attr'] for i in range(len(graph.nodes))], dtype=torch.float)\n",
    "x = F.normalize(x, dim=0)\n",
    "mass = torch.tensor([mass[i] for i in range(len(graph.nodes))], dtype=torch.float)\n",
    "\n",
    "num_nodes = len(nodes)\n",
    "train_percentage = 0.8\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "num_train_nodes = int(num_nodes*train_percentage)\n",
    "train_mask[:num_train_nodes] = True\n",
    "test_mask = ~train_mask\n",
    "\n",
    "graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=mass, train_mask=train_mask, test_mask=test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.validate(raise_on_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout_rate=0.5):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.convs = nn.ModuleList([GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers)])\n",
    "        self.bn_layers = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
    "        self.conv_out = GCNConv(hidden_dim, output_dim)\n",
    "        self.dropout = dropout_rate\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = self.bn1(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        for conv, bn in zip(self.convs, self.bn_layers):\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "            x = bn(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv_out(x, edge_index, edge_attr)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOptimizaton:\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout_rate):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def objective(self, trial):\n",
    "        input_dim = trial.suggest_int('input_dim', 1, 10)\n",
    "        hidden_dim = trial.suggest_int('hidden_dim', 8, 124)\n",
    "        output_dim = trial.suggest_int('output_dim', 1, 10)\n",
    "        num_layers = trial.suggest_int('num_layers', 1, 64)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0, 1)\n",
    "        gnn = GNN(self, input_dim, hidden_dim, output_dim, num_layers, dropout_rate)\n",
    "        gnn.fit(self.x_train, self.y_train)\n",
    "        return regressor.score(self.x_test, self.y_test)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    nodes, _, _ = graph_r(rosettes[0])\n",
    "    model = ModelOptimizaton(x_train, x_test, y_train, y_test)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(model.objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, hidden_dim, output_dim, num_layers = 6, 64, 1, 2\n",
    "model = GNN(input_dim, hidden_dim, output_dim, num_layers, dropout_rate=0.5)\n",
    "\n",
    "print(model)\n",
    "print(f'Parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "tcv = make_dot(model(graph), params=dict(list(model.named_parameters()))).render(\"./torchviz/gnn_torchviz\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
